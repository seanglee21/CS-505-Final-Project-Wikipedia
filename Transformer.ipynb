{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvla92Lh2urb"
      },
      "source": [
        "## Transformer for Generation from Wikipedia Tiltles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rn5NPiyx2urf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkuKBX2A2urg"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('wikipedia_data10K.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05TLfuFG3kwW",
        "outputId": "3498084c-4b15-4182-ca71-1de1016a6cab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\TaiSh\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling, GPT2Tokenizer, GPT2LMHeadModel, pipeline, AutoTokenizer\n",
        "import datasets\n",
        "from datasets import load_dataset, list_datasets\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXsRqUt9hvTJ"
      },
      "outputs": [],
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.3, random_state=42)\n",
        "# Reduce the size of the datasets to 3000 samples each\n",
        "train_df = train_df.sample(n=1000, random_state=42)\n",
        "val_df = val_df.sample(n=200, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "jA4v6qge4Pj-",
        "outputId": "a8e2e1e0-c44e-4adf-f90c-4c7a0696d4a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\anaconda3\\envs\\conda310\\lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if _pandas_api.is_sparse(col):\n",
            "Map: 100%|██████████| 1000/1000 [00:06<00:00, 162.10 examples/s]\n",
            "Map: 100%|██████████| 200/200 [00:01<00:00, 186.77 examples/s]\n",
            "100%|██████████| 62/62 [52:51<00:00, 51.15s/it] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 3171.1588, 'train_samples_per_second': 0.315, 'train_steps_per_second': 0.02, 'train_loss': 3.3326201900359123, 'epoch': 0.99}\n"
          ]
        }
      ],
      "source": [
        "# Create the AutoTokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2').cuda()\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# Define the function to encode your data\n",
        "def encode(batch):\n",
        "    return tokenizer([x.strip('\\n\\r') for x in batch['Text']], truncation=True, padding=True)\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "dataset = Dataset.from_pandas(train_df)\n",
        "processed_dataset = dataset.map(encode, batched=True, batch_size=len(dataset))\n",
        "processed_dataset.set_format('torch', columns=['input_ids', 'attention_mask'])\n",
        "\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "processed_val_dataset = val_dataset.map(encode, batched=True, batch_size=len(val_dataset))\n",
        "processed_val_dataset.set_format('torch', columns=['input_ids', 'attention_mask'])\n",
        "\n",
        "# Load and fine-tune the GPT-2 model\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='/content/',\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=32,\n",
        "    logging_steps=100,\n",
        "    weight_decay=0.01,\n",
        "    gradient_accumulation_steps=2,\n",
        "    logging_dir='./logs',\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=processed_dataset,\n",
        "    eval_dataset=processed_val_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_model('./trc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "Ch0gKG5haMWY",
        "outputId": "984b9862-f7b2-46db-d98e-4e13daaeb031"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   1456 MiB |  26142 MiB |  12308 GiB |  12307 GiB |\\n|       from large pool |   1443 MiB |  26126 MiB |  12308 GiB |  12306 GiB |\\n|       from small pool |     13 MiB |     15 MiB |      0 GiB |      0 GiB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   1456 MiB |  26142 MiB |  12308 GiB |  12307 GiB |\\n|       from large pool |   1443 MiB |  26126 MiB |  12308 GiB |  12306 GiB |\\n|       from small pool |     13 MiB |     15 MiB |      0 GiB |      0 GiB |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |   1452 MiB |  26131 MiB |  12307 GiB |  12306 GiB |\\n|       from large pool |   1438 MiB |  26115 MiB |  12307 GiB |  12305 GiB |\\n|       from small pool |     13 MiB |     15 MiB |      0 GiB |      0 GiB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |  26406 MiB |  26406 MiB |  26406 MiB |      0 B   |\\n|       from large pool |  26390 MiB |  26390 MiB |  26390 MiB |      0 B   |\\n|       from small pool |     16 MiB |     16 MiB |     16 MiB |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   1289 MiB |   5602 MiB |   3936 GiB |   3935 GiB |\\n|       from large pool |   1288 MiB |   5600 MiB |   3935 GiB |   3934 GiB |\\n|       from small pool |      0 MiB |      2 MiB |      0 GiB |      0 GiB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     470    |     923    |  149519    |  149049    |\\n|       from large pool |     152    |     436    |  110140    |  109988    |\\n|       from small pool |     318    |     519    |   39379    |   39061    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     470    |     923    |  149519    |  149049    |\\n|       from large pool |     152    |     436    |  110140    |  109988    |\\n|       from small pool |     318    |     519    |   39379    |   39061    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     140    |     140    |     140    |       0    |\\n|       from large pool |     132    |     132    |     132    |       0    |\\n|       from small pool |       8    |       8    |       8    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      42    |      77    |   51290    |   51248    |\\n|       from large pool |      34    |      56    |   34728    |   34694    |\\n|       from small pool |       8    |      21    |   16562    |   16554    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKrCwXSShvTM",
        "outputId": "e4bbc80b-9c77-46b0-c65a-b0a42f82dae1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': 'Virtual Box and Windows Server 2012 for Windows Server 2012 R2 (6-10) on x64 Windows Server 2012 (4-7) x64 Windows Server 2012 R2 (6-10) Enterprise Linux for Windows Server 2012 R2 on 4'}]\n",
            "[{'generated_text': 'Virtual Box is the official virtual box for PlayStation Portable 2, designed by Yoshikazu Takazawa and announced for consoles on September 7, 2013. Its predecessor to the original PlayStation Portable was released on April 27, 2013, and was made available'}]\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "gpt2 = pipeline('text-generation', model='gpt2', device=0)\n",
        "trc = pipeline('text-generation', model='trc', device=0)\n",
        "\n",
        "print(gpt2('Virtual Box'))\n",
        "print(trc('Virtual Box'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqYpTUErhvTN",
        "outputId": "ea7e4d51-f0b7-45fc-c83b-aabcbbccaaf6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\TaiSh\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': \"Phoenix Wright: Ace Attorney - Spirit of Justice - Star of Time Battleship Zero (2001)\\n\\n\\nAce Attorney - The Ultimate Fighter (2002)\\n\\n\\nKangaroo Court: The World's Greatest Trial (2003)\\n\\n\\nFate\"}]\n",
            "[{'generated_text': 'Phoenix Wright: Ace Attorney - Spirit of Justice, 1995, as Airtel, $10. ISBN 978-0-7868-5543-5. © Ace Attorney Productions, 1997; Ace Attorney: Spirit of Justice, 1998; Ace'}]\n"
          ]
        }
      ],
      "source": [
        "print(gpt2('Phoenix Wright: Ace Attorney - Spirit of Justice'))\n",
        "print(trc('Phoenix Wright: Ace Attorney - Spirit of Justice'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_csM5ishvTN",
        "outputId": "9e997e72-8c0a-428f-fe30-1875b7eb6b2f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': 'Ammonium sulfate precipitation or mineral precipitation (m-SO 4 -fluoride), m-OH 4 (r-OH 4 ), and m-CH 3 :H 3 O 4 are the primary drivers of the precipitation. We found that'}]\n",
            "[{'generated_text': 'Ammonium sulfate precipitation in the North (NPS). Credit: NASA/JPL-Caltech, NASA, and the European Space Agency. The climate model in this study is adapted from a work published in 2007. The first draft of'}]\n"
          ]
        }
      ],
      "source": [
        "print(gpt2('Ammonium sulfate precipitation'))\n",
        "print(trc('Ammonium sulfate precipitation'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIZ_2kN3hvTO",
        "outputId": "275cd22f-9376-4fee-adda-64107732fd14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': 'Heartbeat (British TV series)\\n\\nIn this comedy - about a young boy who seeks help from his mentor, who has been kidnapped and rescued by the mysterious M.P.E.S. (Mutant Mobs) - the boys'}]\n",
            "[{'generated_text': 'Heartbeat (British TV series) In the Season 3 episode \"No Way Out\" (\"A Very Long Time\"), Amy gets a call about a very long time ago - only to hear she isn\\'t going to get the job. She calls back to'}]\n"
          ]
        }
      ],
      "source": [
        "print(gpt2('Heartbeat (British TV series)'))\n",
        "print(trc('Heartbeat (British TV series)'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}