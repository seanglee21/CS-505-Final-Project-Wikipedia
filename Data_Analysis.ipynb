{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Title  \\\n",
      "0  Phoenix Wright: Ace Attorney – Spirit of Justice   \n",
      "1                    Ammonium sulfate precipitation   \n",
      "2                            Kinki (disambiguation)   \n",
      "3                     Heartbeat (British TV series)   \n",
      "4                                             Uolba   \n",
      "\n",
      "                                                Text  \n",
      "0  2016 video game 2016 video game Phoenix Wright...  \n",
      "1  Ammonium sulfate precipitation is one of the m...  \n",
      "2  Kinki may refer to: Kansai region , Japan; als...  \n",
      "3  British television drama series (1992–2010) Th...  \n",
      "4  Selo in Sakha Republic, Russia Uolba Уолба Sel...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('wikipedia_data10K.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The title and text were both initially stored as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of title: \n",
      "<class 'str'>\n",
      "Type of text: \n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print('Type of title: ')\n",
    "print(type(df['Title'][0]))\n",
    "print('Type of text: ')\n",
    "print(type(df['Text'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collection algorithm was supposed to collect first 1000 words in each article. The reason the average number of words in an article may be lower is because many articles may have less than 1000 words in an article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of words in each article title is: 2.8973\n",
      "The average number of words in each article is: 599.838\n"
     ]
    }
   ],
   "source": [
    "title_word_sum = 0\n",
    "text_word_sum = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    title_word_sum += len(row['Title'].split())\n",
    "    text_word_sum += len(row['Text'].split())\n",
    "    \n",
    "title_avg_word_length = title_word_sum / df.shape[0]\n",
    "text_avg_word_length = text_word_sum / df.shape[0]\n",
    "    \n",
    "print(f'The average number of words in each article title is: {title_avg_word_length}')\n",
    "print(f'The average number of words in each article is: {text_avg_word_length}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average title length is: 20.0032 characters\n",
      "The average text length is: 3676.5312 characters\n"
     ]
    }
   ],
   "source": [
    "title_avg_char_length = df['Title'].str.len().sum() / df.shape[0] \n",
    "text_avg_char_length = df['Text'].str.len().sum() / df.shape[0] \n",
    "\n",
    "print(f'The average title length is: {title_avg_char_length} characters')\n",
    "print(f'The average text length is: {text_avg_char_length} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique characters in article titles is: 181\n",
      "The number of unique words in article titles is: 15843\n",
      "The number of unique characters in the article text is: 4526\n",
      "The number of unique words in the article text is: 599970\n"
     ]
    }
   ],
   "source": [
    "unique_title_words = set()\n",
    "unique_text_words = set()\n",
    "unique_title_chars = set()\n",
    "unique_text_chars = set()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    for c in row['Title']:\n",
    "        if c not in unique_title_chars:\n",
    "            unique_title_chars.add(c)\n",
    "    for word in row['Title'].split():\n",
    "        if word not in unique_title_words:\n",
    "            unique_title_words.add(word)\n",
    "    for c in row['Text']:\n",
    "        if c not in unique_text_chars:\n",
    "            unique_text_chars.add(c)\n",
    "    for word in row['Text'].split():\n",
    "        if word not in unique_text_words:\n",
    "            unique_text_words.add(word)\n",
    "            \n",
    "print(f'The number of unique characters in article titles is: {len(unique_title_chars)}')\n",
    "print(f'The number of unique words in article titles is: {len(unique_title_words)}')\n",
    "print(f'The number of unique characters in the article text is: {len(unique_text_chars)}')\n",
    "print(f'The number of unique words in the article text is: {len(unique_text_words)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
